{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_excel('data/train_prepped.xlsx')\n",
    "# validation_df = pd.read_excel('data/validation_prepped.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel('data/train_scaled.xlsx')\n",
    "validation_df = pd.read_excel('data/validation_scaled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing(data):\n",
    "# Identify missing data\n",
    "    missing_data = data.isnull().sum()\n",
    "    missing_percent = (data.isnull().sum() / len(data)) * 100\n",
    "\n",
    "    # Create a DataFrame for missing data\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Total': missing_data,\n",
    "        'Percent': missing_percent\n",
    "    })\n",
    "    # Display columns with missing values\n",
    "    return missing_df[missing_df['Total'] > 0].sort_values(by=\"Total\", ascending=False)\n",
    "\n",
    "missing(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.copy()\n",
    "validation = validation_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['blue_fighter_weight', 'red_fighter_weight']\n",
    "\n",
    "train = train.drop(columns=[col for col in columns_to_drop if col in train.columns])\n",
    "validation = validation.drop(columns=[col for col in columns_to_drop if col in validation.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo\n",
    "-   imbalanced?\n",
    "-   why the order of the fighters is important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symmetric GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "def swap_red_blue_columns(df):\n",
    "    \"\"\"\n",
    "    Swap red and blue columns in the dataframe\n",
    "    \n",
    "    Args:\n",
    "        df: Original dataframe\n",
    "        \n",
    "    Returns:\n",
    "        A new dataframe with red and blue columns swapped\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df_mod = df.copy()\n",
    "    \n",
    "    # Identify columns that need to be swapped (those with 'red' or 'blue' in their names)\n",
    "    red_cols = [col for col in df.columns if 'red' in col]\n",
    "    blue_cols = [col for col in df.columns if 'blue' in col]\n",
    "    \n",
    "    # Create mapping for column renaming\n",
    "    rename_dict = {}\n",
    "    \n",
    "    # For each red column, find the corresponding blue column\n",
    "    for red_col in red_cols:\n",
    "        # Replace 'red' with 'blue' to get the corresponding blue column name\n",
    "        blue_col = red_col.replace('red', 'blue')\n",
    "        \n",
    "        # Check if the corresponding blue column exists\n",
    "        if blue_col in blue_cols:\n",
    "            # Add to rename dictionary (we'll do a two-step rename to avoid conflicts)\n",
    "            rename_dict[red_col] = f\"temp_{red_col}\"\n",
    "            rename_dict[blue_col] = f\"temp_{blue_col}\"\n",
    "    \n",
    "    # First step: rename to temporary names\n",
    "    df_mod.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    # Second step: rename from temporary names to swapped names\n",
    "    second_rename = {}\n",
    "    for orig_col, temp_col in rename_dict.items():\n",
    "        if 'red' in orig_col:\n",
    "            # This was a red column, now should be blue\n",
    "            second_rename[temp_col] = orig_col.replace('red', 'blue')\n",
    "        else:\n",
    "            # This was a blue column, now should be red\n",
    "            second_rename[temp_col] = orig_col.replace('blue', 'red')\n",
    "    \n",
    "    df_mod.rename(columns=second_rename, inplace=True)\n",
    "    \n",
    "    # For target column, we need to invert it (1 becomes 0, 0 becomes 1)\n",
    "    if 'target' in df_mod.columns:\n",
    "        df_mod['target'] = 1 - df_mod['target']\n",
    "    \n",
    "    return df_mod\n",
    "\n",
    "def augment_training_data(train_df):\n",
    "    \"\"\"\n",
    "    Augment training data by adding swapped versions of each matchup\n",
    "    \"\"\"\n",
    "    # Create swapped version of the training data\n",
    "    train_swapped = swap_red_blue_columns(train_df)\n",
    "    \n",
    "    # Concatenate original and swapped data\n",
    "    augmented_train = pd.concat([train_df, train_swapped], ignore_index=True)\n",
    "    \n",
    "    return augmented_train\n",
    "\n",
    "def create_ufc_graph(df):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Get unique fighters and create nodes\n",
    "    fighters = set(df['red_fighter_name'].unique()) | set(df['blue_fighter_name'].unique())\n",
    "    \n",
    "    # Create nodes (no features needed)\n",
    "    for fighter in fighters:\n",
    "        G.add_node(fighter)\n",
    "    \n",
    "    # Get all columns except fighter names and event_date (will be used only for splitting)\n",
    "    edge_feature_cols = [col for col in df.columns if col not in ['red_fighter_name', 'blue_fighter_name', 'event_date']]\n",
    "    \n",
    "    # Add edges with features\n",
    "    for _, row in df.iterrows():\n",
    "        red_fighter = row['red_fighter_name']\n",
    "        blue_fighter = row['blue_fighter_name']\n",
    "        \n",
    "        # Create edge features dictionary\n",
    "        edge_features = {}\n",
    "        for col in edge_feature_cols:\n",
    "            value = row[col]\n",
    "            if isinstance(value, bool):\n",
    "                edge_features[col] = float(value)\n",
    "            elif isinstance(value, (int, float)):\n",
    "                edge_features[col] = float(value)\n",
    "            else:\n",
    "                try:\n",
    "                    edge_features[col] = float(value)\n",
    "                except:\n",
    "                    continue  # Skip features that can't be converted to float\n",
    "        \n",
    "        # Add event_date as metadata but not as a feature\n",
    "        if 'event_date' in df.columns:\n",
    "            edge_features['_event_date'] = row['event_date']  # Prefix with _ to indicate metadata\n",
    "        \n",
    "        G.add_edge(red_fighter, blue_fighter, **edge_features)\n",
    "    \n",
    "    return G, edge_feature_cols\n",
    "\n",
    "def create_pytorch_geometric_data(G, edge_feature_cols):\n",
    "    # Create node index mapping\n",
    "    node_idx = {node: idx for idx, node in enumerate(G.nodes())}\n",
    "    \n",
    "    # Create edge index and edge features\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    edge_dates = []  # To store dates for time-based splitting\n",
    "    \n",
    "    for u, v, data in G.edges(data=True):\n",
    "        # Add edge indices (both directions since it's undirected)\n",
    "        edge_index.append([node_idx[u], node_idx[v]])\n",
    "        edge_index.append([node_idx[v], node_idx[u]])  # Add reverse edge\n",
    "        \n",
    "        # Store event date if available (for time-based splitting)\n",
    "        if '_event_date' in data:\n",
    "            edge_dates.append(data['_event_date'])\n",
    "            edge_dates.append(data['_event_date'])  # Duplicate for reverse edge\n",
    "        \n",
    "        # Add edge features (excluding metadata)\n",
    "        edge_feat = [data.get(col, 0.0) for col in edge_feature_cols if not col.startswith('_')]\n",
    "        edge_features.append(edge_feat)\n",
    "        edge_features.append(edge_feat)  # Duplicate for reverse edge\n",
    "    \n",
    "    # Convert to tensors\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_features = torch.tensor(edge_features, dtype=torch.float)\n",
    "    \n",
    "    # Create PyG Data object (no node features)\n",
    "    num_nodes = len(node_idx)\n",
    "    data = Data(\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_features,\n",
    "        num_nodes=num_nodes\n",
    "    )\n",
    "    \n",
    "    return data, node_idx, edge_dates\n",
    "\n",
    "class SymmetricFighterEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A symmetric encoder for fighter embeddings that ensures both fighters\n",
    "    are processed in exactly the same way.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_channels=1024):\n",
    "        super(SymmetricFighterEncoder, self).__init__()\n",
    "        \n",
    "        # GCN layers (no node features input, using constant 1s)\n",
    "        self.conv1 = GCNConv(1, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels//2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # Node feature processing through GCN layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class SymmetricUFCNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A symmetric UFC prediction model that treats both fighters equally\n",
    "    \"\"\"\n",
    "    def __init__(self, num_edge_features, hidden_channels=1024):\n",
    "        super(SymmetricUFCNet, self).__init__()\n",
    "        \n",
    "        # Shared fighter encoder\n",
    "        self.fighter_encoder = SymmetricFighterEncoder(hidden_channels)\n",
    "        \n",
    "        # Edge feature processing\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(num_edge_features, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels//2)\n",
    "        )\n",
    "        \n",
    "        # Final prediction layers\n",
    "        combined_size = hidden_channels//2 * 2 + hidden_channels//2  # node embeddings * 2 + edge features\n",
    "        self.final_mlp = nn.Sequential(\n",
    "            nn.Linear(combined_size, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_channels, 2),  # 2 outputs: red win and blue win probabilities\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # Create placeholder node features (all 1s)\n",
    "        x = torch.ones((data.num_nodes, 1), device=data.edge_index.device)\n",
    "        edge_index, edge_attr = data.edge_index, data.edge_attr\n",
    "        \n",
    "        # Get fighter embeddings using the shared encoder\n",
    "        fighter_embeddings = self.fighter_encoder(x, edge_index)\n",
    "        \n",
    "        # Process edge features\n",
    "        edge_features = self.edge_mlp(edge_attr)\n",
    "        \n",
    "        # For each edge, combine features of both nodes and edge\n",
    "        src_nodes = edge_index[0]  # Source nodes (red fighters)\n",
    "        dst_nodes = edge_index[1]  # Destination nodes (blue fighters)\n",
    "        \n",
    "        # Combine features\n",
    "        src_features = fighter_embeddings[src_nodes]\n",
    "        dst_features = fighter_embeddings[dst_nodes]\n",
    "        combined_features = torch.cat([src_features, dst_features, edge_features], dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        predictions = self.final_mlp(combined_features)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "def train_model(model, data, edge_dates=None, test_percent=0.2, num_epochs=150):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Get target values from edge attributes (assuming 'target' is one of the edge features)\n",
    "    target_idx = None\n",
    "    for i, col in enumerate(edge_feature_cols):\n",
    "        if col == 'target':\n",
    "            target_idx = i\n",
    "            break\n",
    "    \n",
    "    if target_idx is None:\n",
    "        raise ValueError(\"Target column not found in edge features\")\n",
    "    \n",
    "    # Create targets for both red and blue\n",
    "    red_target = data.edge_attr[:, target_idx].float().unsqueeze(1)\n",
    "    blue_target = 1 - red_target  # Blue win is the opposite of red win\n",
    "    \n",
    "    # Combine targets\n",
    "    y = torch.cat([red_target, blue_target], dim=1)\n",
    "    \n",
    "    # Split data into train and test sets based on dates if available\n",
    "    num_edges = data.edge_index.size(1)\n",
    "    \n",
    "    if edge_dates:\n",
    "        # Convert to pandas Series for easier sorting\n",
    "        dates_series = pd.Series(edge_dates)\n",
    "        # Get indices sorted by date\n",
    "        sorted_indices = dates_series.sort_values().index\n",
    "        # Take the newest X% as test set\n",
    "        test_size = int(test_percent * num_edges)\n",
    "        test_indices = sorted_indices[-test_size:]\n",
    "        train_indices = sorted_indices[:-test_size]\n",
    "    else:\n",
    "        # Random split if dates not available\n",
    "        indices = torch.randperm(num_edges)\n",
    "        train_size = int((1 - test_percent) * num_edges)\n",
    "        train_indices = indices[:train_size]\n",
    "        test_indices = indices[train_size:]\n",
    "    \n",
    "    # Create masks\n",
    "    train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "    train_mask[train_indices] = True\n",
    "    test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "    test_mask[test_indices] = True\n",
    "    \n",
    "    # Move everything to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    data = data.to(device)\n",
    "    y = y.to(device)\n",
    "    train_mask = train_mask.to(device)\n",
    "    test_mask = test_mask.to(device)\n",
    "    \n",
    "    # Calculate class weights to handle imbalance\n",
    "    # Count class occurrences in the training set\n",
    "    red_count = y[train_mask, 0].sum().item()\n",
    "    blue_count = y[train_mask, 1].sum().item()\n",
    "    total_count = len(train_indices)\n",
    "    \n",
    "    # Calculate weights inversely proportional to class frequencies\n",
    "    red_weight = total_count / (2 * red_count)\n",
    "    blue_weight = total_count / (2 * blue_count)\n",
    "    \n",
    "    # Create weight tensor for loss function\n",
    "    pos_weight = torch.tensor([red_weight/blue_weight, blue_weight/red_weight], device=device)\n",
    "    \n",
    "    # Use weighted BCE loss\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    \n",
    "    best_test_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    # Lists to store metrics for plotting\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    red_train_accs = []\n",
    "    red_test_accs = []\n",
    "    blue_train_accs = []\n",
    "    blue_test_accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data)\n",
    "        loss = criterion(out[train_mask], y[train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Testing\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = criterion(out[test_mask], y[test_mask])\n",
    "            \n",
    "            # Calculate accuracy for red win prediction\n",
    "            pred_probs = torch.sigmoid(out)\n",
    "            red_pred_labels = (pred_probs[:, 0] > 0.5).float()\n",
    "            blue_pred_labels = (pred_probs[:, 1] > 0.5).float()\n",
    "            \n",
    "            red_train_acc = (red_pred_labels[train_mask] == y[train_mask, 0]).float().mean()\n",
    "            red_test_acc = (red_pred_labels[test_mask] == y[test_mask, 0]).float().mean()\n",
    "            \n",
    "            blue_train_acc = (blue_pred_labels[train_mask] == y[train_mask, 1]).float().mean()\n",
    "            blue_test_acc = (blue_pred_labels[test_mask] == y[test_mask, 1]).float().mean()\n",
    "            \n",
    "            # Store metrics for plotting\n",
    "            train_losses.append(loss.item())\n",
    "            test_losses.append(test_loss.item())\n",
    "            red_train_accs.append(red_train_acc.item())\n",
    "            red_test_accs.append(red_test_acc.item())\n",
    "            blue_train_accs.append(blue_train_acc.item())\n",
    "            blue_test_accs.append(blue_test_acc.item())\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1:03d}, Train Loss: {loss:.4f}, Test Loss: {test_loss:.4f}, \"\n",
    "                  f\"Red Train Acc: {red_train_acc:.4f}, Red Test Acc: {red_test_acc:.4f}, \"\n",
    "                  f\"Blue Train Acc: {blue_train_acc:.4f}, Blue Test Acc: {blue_test_acc:.4f}\")\n",
    "        \n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    # Plot training and test loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(test_losses, label='Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Test Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(red_train_accs, label='Red Train Acc')\n",
    "    plt.plot(red_test_accs, label='Red Test Acc')\n",
    "    plt.plot(blue_train_accs, label='Blue Train Acc')\n",
    "    plt.plot(blue_test_accs, label='Blue Test Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Test Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the model and the metrics for further analysis\n",
    "    metrics = {\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'red_train_accs': red_train_accs,\n",
    "        'red_test_accs': red_test_accs,\n",
    "        'blue_train_accs': blue_train_accs,\n",
    "        'blue_test_accs': blue_test_accs\n",
    "    }\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "def predict_validation(model, train_data, node_idx, validation_df):\n",
    "    \"\"\"\n",
    "    Predict outcomes for validation data\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    \n",
    "    # Create predictions dataframe\n",
    "    predictions_df = validation_df[['red_fighter_name', 'blue_fighter_name']].copy()\n",
    "    predictions_df['red_win_prob'] = None\n",
    "    predictions_df['blue_win_prob'] = None\n",
    "    \n",
    "    # Create placeholder node features\n",
    "    x = torch.ones((train_data.num_nodes, 1), device=device)\n",
    "    \n",
    "    # Get node embeddings from trained model\n",
    "    with torch.no_grad():\n",
    "        edge_index = train_data.edge_index.to(device)\n",
    "        fighter_embeddings = model.fighter_encoder(x, edge_index)\n",
    "    \n",
    "    # Process each matchup in validation set\n",
    "    for idx, row in validation_df.iterrows():\n",
    "        red_fighter = row['red_fighter_name']\n",
    "        blue_fighter = row['blue_fighter_name']\n",
    "        \n",
    "        # Skip if either fighter is not in the training graph\n",
    "        if red_fighter not in node_idx or blue_fighter not in node_idx:\n",
    "            continue\n",
    "        \n",
    "        # Get node embeddings\n",
    "        red_emb = fighter_embeddings[node_idx[red_fighter]].unsqueeze(0)\n",
    "        blue_emb = fighter_embeddings[node_idx[blue_fighter]].unsqueeze(0)\n",
    "        \n",
    "        # Create edge features\n",
    "        edge_features = []\n",
    "        for col in edge_feature_cols:\n",
    "            if col in validation_df.columns and col != 'target' and col != 'event_date':\n",
    "                try:\n",
    "                    value = float(row[col])\n",
    "                    edge_features.append(value)\n",
    "                except:\n",
    "                    edge_features.append(0.0)  # Default value\n",
    "            else:\n",
    "                edge_features.append(0.0)  # Default value\n",
    "        \n",
    "        edge_tensor = torch.tensor([edge_features], dtype=torch.float, device=device)\n",
    "        edge_emb = model.edge_mlp(edge_tensor)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat([red_emb, blue_emb, edge_emb], dim=1)\n",
    "        \n",
    "        # Get prediction\n",
    "        logits = model.final_mlp(combined)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        # Store predictions\n",
    "        predictions_df.loc[idx, 'red_win_prob'] = probs[0, 0].item()\n",
    "        predictions_df.loc[idx, 'blue_win_prob'] = probs[0, 1].item()\n",
    "        \n",
    "        # Also predict with swapped positions for symmetry check\n",
    "        swapped_combined = torch.cat([blue_emb, red_emb, edge_emb], dim=1)\n",
    "        swapped_logits = model.final_mlp(swapped_combined)\n",
    "        swapped_probs = torch.sigmoid(swapped_logits)\n",
    "        \n",
    "        # Store swapped predictions\n",
    "        predictions_df.loc[idx, 'swapped_blue_win_prob'] = swapped_probs[0, 0].item()\n",
    "        predictions_df.loc[idx, 'swapped_red_win_prob'] = swapped_probs[0, 1].item()\n",
    "        \n",
    "        # Calculate symmetry metrics\n",
    "        predictions_df.loc[idx, 'red_blue_diff'] = abs(predictions_df.loc[idx, 'red_win_prob'] - \n",
    "                                                      predictions_df.loc[idx, 'swapped_blue_win_prob'])\n",
    "        predictions_df.loc[idx, 'blue_red_diff'] = abs(predictions_df.loc[idx, 'blue_win_prob'] - \n",
    "                                                      predictions_df.loc[idx, 'swapped_red_win_prob'])\n",
    "    \n",
    "    return predictions_df\n",
    "\n",
    "# Main execution flow\n",
    "# 1. Augment training data by adding swapped versions\n",
    "train_augmented = augment_training_data(train)\n",
    "print(f\"Original training data size: {len(train)}\")\n",
    "print(f\"Augmented training data size: {len(train_augmented)}\\n\")\n",
    "\n",
    "# 2. Create graph from augmented training data\n",
    "G, edge_feature_cols = create_ufc_graph(train_augmented)\n",
    "\n",
    "# 3. Convert to PyTorch Geometric data\n",
    "data, node_idx, edge_dates = create_pytorch_geometric_data(G, edge_feature_cols)\n",
    "\n",
    "# 4. Initialize and train symmetric model\n",
    "model = SymmetricUFCNet(num_edge_features=len(edge_feature_cols))\n",
    "trained_model, training_metrics = train_model(model, data, edge_dates=edge_dates, test_percent=0.01, num_epochs=300)\n",
    "\n",
    "\n",
    "# 5. Predict on validation set\n",
    "validation_predictions = predict_validation(trained_model, data, node_idx, validation)\n",
    "validation_swapped_symm = swap_red_blue_columns(validation)\n",
    "validation_swapped_symm_prediction = predict_validation(trained_model, data, node_idx, validation_swapped_symm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_predictions(original_predictions, swapped_predictions):\n",
    "    \"\"\"\n",
    "    Average the predictions from original validation data and swapped validation data\n",
    "    to create more symmetric final predictions.\n",
    "    \n",
    "    Args:\n",
    "        original_predictions: DataFrame with predictions on original validation data\n",
    "        swapped_predictions: DataFrame with predictions on swapped validation data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with averaged predictions\n",
    "    \"\"\"\n",
    "    # Create a copy of the original predictions dataframe\n",
    "    averaged_predictions = original_predictions[['red_fighter_name', 'blue_fighter_name']].copy()\n",
    "    \n",
    "    # Initialize columns for the averaged predictions\n",
    "    averaged_predictions['red_win_prob'] = None\n",
    "    averaged_predictions['blue_win_prob'] = None\n",
    "    averaged_predictions['red_blue_diff'] = None\n",
    "    averaged_predictions['blue_red_diff'] = None\n",
    "    \n",
    "    # Create a mapping for swapped predictions to make lookup easier\n",
    "    # Key: (blue_fighter, red_fighter), Value: (red_win_prob, blue_win_prob)\n",
    "    swapped_map = {}\n",
    "    for _, row in swapped_predictions.iterrows():\n",
    "        swapped_map[(row['red_fighter_name'], row['blue_fighter_name'])] = (\n",
    "            row['red_win_prob'], row['blue_win_prob']\n",
    "        )\n",
    "    \n",
    "    # For each row in the original predictions\n",
    "    for idx, row in averaged_predictions.iterrows():\n",
    "        red_fighter = row['red_fighter_name']\n",
    "        blue_fighter = row['blue_fighter_name']\n",
    "        \n",
    "        # Get the original predictions, default to None if not available\n",
    "        try:\n",
    "            orig_red_win = original_predictions.loc[idx, 'red_win_prob']\n",
    "            orig_blue_win = original_predictions.loc[idx, 'blue_win_prob']\n",
    "        except:\n",
    "            orig_red_win = None\n",
    "            orig_blue_win = None\n",
    "        \n",
    "        # Look for the swapped matchup (blue fighter as red, red fighter as blue)\n",
    "        if (blue_fighter, red_fighter) in swapped_map:\n",
    "            # Get the swapped predictions\n",
    "            swapped_red_win, swapped_blue_win = swapped_map[(blue_fighter, red_fighter)]\n",
    "            \n",
    "            # The swapped red_win is actually for the blue fighter in the original\n",
    "            # and the swapped blue_win is for the red fighter in the original\n",
    "            # So we need to swap them back\n",
    "            swapped_red_win_corrected = swapped_blue_win  # Blue in swapped is red in original\n",
    "            swapped_blue_win_corrected = swapped_red_win  # Red in swapped is blue in original\n",
    "            \n",
    "            # Average the predictions, handling None values\n",
    "            if orig_red_win is not None and swapped_red_win_corrected is not None:\n",
    "                avg_red_win = (float(orig_red_win) + float(swapped_red_win_corrected)) / 2\n",
    "                averaged_predictions.at[idx, 'red_win_prob'] = avg_red_win\n",
    "                averaged_predictions.at[idx, 'red_blue_diff'] = abs(float(orig_red_win) - float(swapped_red_win_corrected))\n",
    "            elif orig_red_win is not None:\n",
    "                averaged_predictions.at[idx, 'red_win_prob'] = float(orig_red_win)\n",
    "            elif swapped_red_win_corrected is not None:\n",
    "                averaged_predictions.at[idx, 'red_win_prob'] = float(swapped_red_win_corrected)\n",
    "            \n",
    "            if orig_blue_win is not None and swapped_blue_win_corrected is not None:\n",
    "                avg_blue_win = (float(orig_blue_win) + float(swapped_blue_win_corrected)) / 2\n",
    "                averaged_predictions.at[idx, 'blue_win_prob'] = avg_blue_win\n",
    "                averaged_predictions.at[idx, 'blue_red_diff'] = abs(float(orig_blue_win) - float(swapped_blue_win_corrected))\n",
    "            elif orig_blue_win is not None:\n",
    "                averaged_predictions.at[idx, 'blue_win_prob'] = float(orig_blue_win)\n",
    "            elif swapped_blue_win_corrected is not None:\n",
    "                averaged_predictions.at[idx, 'blue_win_prob'] = float(swapped_blue_win_corrected)\n",
    "        else:\n",
    "            # If no matching swapped prediction, use original if available\n",
    "            if orig_red_win is not None:\n",
    "                averaged_predictions.at[idx, 'red_win_prob'] = float(orig_red_win)\n",
    "            if orig_blue_win is not None:\n",
    "                averaged_predictions.at[idx, 'blue_win_prob'] = float(orig_blue_win)\n",
    "    \n",
    "    return averaged_predictions\n",
    "\n",
    "# Usage example:\n",
    "averaged_results = average_predictions(validation_predictions, validation_swapped_symm_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also create more detailed plots if needed\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(training_metrics['train_losses'], label='Train Loss')\n",
    "plt.plot(training_metrics['test_losses'], label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Red accuracy plot\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(training_metrics['red_train_accs'], label='Red Train Acc')\n",
    "plt.plot(training_metrics['red_test_accs'], label='Red Test Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Red Win Prediction Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Blue accuracy plot\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(training_metrics['blue_train_accs'], label='Blue Train Acc')\n",
    "plt.plot(training_metrics['blue_test_accs'], label='Blue Test Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Blue Win Prediction Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Combined accuracy plot\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(training_metrics['red_train_accs'], label='Red Train Acc')\n",
    "plt.plot(training_metrics['red_test_accs'], label='Red Test Acc')\n",
    "plt.plot(training_metrics['blue_train_accs'], label='Blue Train Acc')\n",
    "plt.plot(training_metrics['blue_test_accs'], label='Blue Test Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('All Accuracy Metrics')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
